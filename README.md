# llm-token-saver-rs

Rust crate for reducing LLM token consumption in production applications.

## Features
- Prompt compression & summarization
- Prefix/context caching
- Selective token injection (playbook-style)
- Dynamic truncation & budgeting
- Token estimation utilities

## Motivation
In snailer.ai (AI coding agent, 5.4K+ downloads), we reduced average token usage by ~30-40% while maintaining response quality.


